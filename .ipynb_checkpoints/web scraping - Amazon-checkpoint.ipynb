{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ab5223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from glob import glob\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ccd783",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers= ({'User-Agent':\n",
    "            'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "            'Accept-Language': 'en-US, en;q=0.5'})\n",
    "\n",
    "url = 'https://www.amazon.com/dp/1501171348?tag=NYTBSREV-20'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8570741f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon = requests.get(url, headers=headers)\n",
    "amazon.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d582f835",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#class=\"size-medium a-color-base a-text-beside-button a-text-bold\"\n",
    "#data-hook=\"acr-average-stars-rating-text\"\n",
    "\n",
    "soup = BeautifulSoup(amazon.content, 'lxml')\n",
    "#stars = soup.select('.data-hook')[0].get_text()\n",
    "#print(stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80b305bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#products = soup.find_all('li', attrs = {'class' : '_a44404 _d85b45'})\n",
    "#products\n",
    "\n",
    "#stars2 = soup.find_all('span', attrs ={'class' : 'size-medium a-color-base a-text-beside-button a-text-bold'})\n",
    "#stars2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8622429e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Last Thing He Told Me: A Novel\n"
     ]
    }
   ],
   "source": [
    "title = soup.find(id='productTitle').get_text().strip()\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30f03ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#priceblock_ourprice\n",
    "#replace('.', '').replace('$', '').replace(',', '.')\n",
    "try:\n",
    "    price =(soup.find('span', attrs = {'class':'a-size-base a-color-price a-color-price'}).get_text())\n",
    "except:\n",
    "    price = 'nothing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91d3d160",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$16.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "208f41fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4\n"
     ]
    }
   ],
   "source": [
    "review_score = float(soup.select('.a-star-4-5')[0].get_text().split(' ')[0].replace(\",\", \".\"))\n",
    "print(review_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7049529c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7146\n"
     ]
    }
   ],
   "source": [
    "review_count = int(soup.select('#acrCustomerReviewText')[0].get_text().split(' ')[0].replace(\",\", \"\"))\n",
    "print(review_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f88574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f95c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_product_list(interval_count = 1, interval_hours = 6):\n",
    "    \"\"\"\n",
    "    This function lods a csv file named TRACKER_PRODUCTS.csv, with headers: [url, code, buy_below]\n",
    "    It looks for the file under in ./trackers\n",
    "    \n",
    "    It also requires a file called SEARCH_HISTORY.xslx under the folder ./search_history to start saving the results.\n",
    "    An empty file can be used on the first time using the script.\n",
    "    \n",
    "    Both the old and the new results are then saved in a new file named SEARCH_HISTORY_{datetime}.xlsx\n",
    "    This is the file the script will use to get the history next time it runs.\n",
    "    Parameters\n",
    "    ----------\n",
    "    interval_count : TYPE, optional\n",
    "        DESCRIPTION. The default is 1. The number of iterations you want the script to run a search on the full list.\n",
    "    interval_hours : TYPE, optional\n",
    "        DESCRIPTION. The default is 6.\n",
    "    Returns\n",
    "    -------\n",
    "    New .xlsx file with previous search history and results from current search\n",
    "    \"\"\"\n",
    "    prod_tracker = pd.read_csv('trackers/TRACKER_PRODUCTS.csv', sep=';')\n",
    "    prod_tracker_URLS = prod_tracker.url\n",
    "    tracker_log = pd.DataFrame()\n",
    "    now = datetime.now().strftime('%Y-%m-%d %Hh%Mm')\n",
    "    interval = 0 # counter reset\n",
    "    \n",
    "    while interval < interval_count:\n",
    "\n",
    "        for x, url in enumerate(prod_tracker_URLS):\n",
    "            page = requests.get(url, headers=HEADERS)\n",
    "            soup = BeautifulSoup(page.content, features=\"lxml\")\n",
    "            \n",
    "            #product title\n",
    "            title = soup.find(id='productTitle').get_text().strip()\n",
    "            \n",
    "            # to prevent script from crashing when there isn't a price for the product\n",
    "            try:\n",
    "                price = float(soup.find(id='priceblock_ourprice').get_text().replace('.', '').replace('â‚¬', '').replace(',', '.').strip())\n",
    "            except:\n",
    "                # this part gets the price in dollars from amazon.com store\n",
    "                try:\n",
    "                    price = float(soup.find(id='priceblock_saleprice').get_text().replace('$', '').replace(',', '').strip())\n",
    "                except:\n",
    "                    price = ''\n",
    "\n",
    "            try:\n",
    "                review_score = float(soup.select('i[class*=\"a-icon a-icon-star a-star-\"]')[0].get_text().split(' ')[0].replace(\",\", \".\"))\n",
    "                review_count = int(soup.select('#acrCustomerReviewText')[0].get_text().split(' ')[0].replace(\".\", \"\"))\n",
    "            except:\n",
    "                # sometimes review_score is in a different position... had to add this alternative with another try statement\n",
    "                try:\n",
    "                    review_score = float(soup.select('i[class*=\"a-icon a-icon-star a-star-\"]')[1].get_text().split(' ')[0].replace(\",\", \".\"))\n",
    "                    review_count = int(soup.select('#acrCustomerReviewText')[0].get_text().split(' ')[0].replace(\".\", \"\"))\n",
    "                except:\n",
    "                    review_score = ''\n",
    "                    review_count = ''\n",
    "            \n",
    "            # checking if there is \"Out of stock\"\n",
    "            try:\n",
    "                soup.select('#availability .a-color-state')[0].get_text().strip()\n",
    "                stock = 'Out of Stock'\n",
    "            except:\n",
    "                # checking if there is \"Out of stock\" on a second possible position\n",
    "                try:\n",
    "                    soup.select('#availability .a-color-price')[0].get_text().strip()\n",
    "                    stock = 'Out of Stock'\n",
    "                except:\n",
    "                    # if there is any error in the previous try statements, it means the product is available\n",
    "                    stock = 'Available'\n",
    "\n",
    "            log = pd.DataFrame({'date': now.replace('h',':').replace('m',''),\n",
    "                                'code': prod_tracker.code[x], # this code comes from the TRACKER_PRODUCTS file\n",
    "                                'url': url,\n",
    "                                'title': title,\n",
    "                                'buy_below': prod_tracker.buy_below[x], # this price comes from the TRACKER_PRODUCTS file\n",
    "                                'price': price,\n",
    "                                'stock': stock,\n",
    "                                'review_score': review_score,\n",
    "                                'review_count': review_count}, index=[x])\n",
    "\n",
    "            try:\n",
    "                # This is where you can integrate an email alert!\n",
    "                if price < prod_tracker.buy_below[x]:\n",
    "                    print('************************ ALERT! Buy the '+prod_tracker.code[x]+' ************************')\n",
    "            \n",
    "            except:\n",
    "                # sometimes we don't get any price, so there will be an error in the if condition above\n",
    "                pass\n",
    "\n",
    "            tracker_log = tracker_log.append(log)\n",
    "            print('appended '+ prod_tracker.code[x] +'\\n' + title + '\\n\\n')            \n",
    "            sleep(5)\n",
    "        \n",
    "        interval += 1# counter update\n",
    "        \n",
    "        sleep(interval_hours*1*1)\n",
    "        print('end of interval '+ str(interval))\n",
    "    \n",
    "    # after the run, checks last search history record, and appends this run results to it, saving a new file\n",
    "    last_search = glob('[REPLACE WITH YOUR OWN PATH -> C:/Amazon Webscraper/search_history/*.xlsx')[-1] # path to file in the folder\n",
    "    search_hist = pd.read_excel(last_search)\n",
    "    final_df = search_hist.append(tracker_log, sort=False)\n",
    "    \n",
    "    final_df.to_excel('search_history/SEARCH_HISTORY_{}.xlsx'.format(now), index=False)\n",
    "    print('end of search')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
